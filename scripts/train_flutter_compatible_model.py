#!/usr/bin/env python3
"""
Flutter-Compatible Soil Detection Model Training
===============================================

Specialized training script that generates TensorFlow Lite models
fully compatible with Flutter's TFLite interpreter.

Key Features:
- Uses ONLY TFLite built-in operations (no SELECT_TF_OPS)
- Avoids BatchNormalization layers that cause compatibility issues
- Generates quantized INT8 models for better mobile performance
- Includes representative dataset for proper quantization
- Creates Flutter-friendly input/output types (UINT8)

Author: Puviyan AI Team
Version: 4.0.0 (Flutter-Compatible)
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import os
import json
from datetime import datetime
import matplotlib.pyplot as plt
import zipfile
from pathlib import Path
import shutil
from PIL import Image
import random
from sklearn.model_selection import train_test_split

# Configuration for Flutter compatibility
MODEL_NAME = "soil_classifier_flutter_compatible"
INPUT_SIZE = 224
NUM_CLASSES = 8
BATCH_SIZE = 64  # Optimized for better GPU utilization and stability
EPOCHS = 100     # Increased for better convergence
LEARNING_RATE = 0.0005  # Reduced for better training stability
PATIENCE = 15     # Early stopping patience
MIN_DELTA = 1e-4  # Minimum change for early stopping

# GPU Optimization Settings
AUTO_BATCH_SIZE = True  # Automatically adjust batch size based on GPU memory
MAX_BATCH_SIZE = 128    # Maximum batch size for high-end GPUs
MIN_BATCH_SIZE = 16     # Minimum batch size for low-memory situations

# Learning rate schedule
def lr_schedule(epoch):
    """Learning rate schedule with warmup and cosine decay"""
    # Warmup for first 5 epochs
    if epoch < 5:
        return LEARNING_RATE * (epoch + 1) / 5
    # Cosine decay
    cos_decay = 0.5 * (1 + np.cos(np.pi * (epoch - 5) / (EPOCHS - 5)))
    return LEARNING_RATE * cos_decay

# Indian soil types
SOIL_LABELS = {
    0: "Alluvial Soil",
    1: "Black Soil", 
    2: "Red Soil",
    3: "Laterite Soil",
    4: "Desert Soil",
    5: "Saline/Alkaline Soil",
    6: "Peaty/Marshy Soil",
    7: "Forest/Hill Soil"
}

def get_data_augmentation():
    """
    Create data augmentation pipeline for training
    
    Returns:
        A Sequential model containing the data augmentation pipeline
    """
    return tf.keras.Sequential([
        # Spatial transformations
        layers.RandomFlip("horizontal_and_vertical"),
        layers.RandomRotation(0.2, fill_mode='reflect'),
        layers.RandomZoom(0.2, fill_mode='reflect'),
        
        # Color transformations
        layers.RandomBrightness(0.15, value_range=(0, 255)),
        layers.RandomContrast(0.2),
        layers.RandomSaturation(0.2),
        layers.RandomHue(0.1),
        
        # Advanced augmentations
        layers.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode='reflect'),
        layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1), fill_mode='reflect'),
        
        # Random quality changes to simulate different camera conditions
        layers.RandomZoom(height_factor=(0.0, 0.2), width_factor=(0.0, 0.2), fill_mode='reflect'),
        
        # Random erasing (cutout)
        layers.RandomZoom(height_factor=(0.8, 1.0), width_factor=(0.8, 1.0), fill_mode='constant', fill_value=0.0),
        
        # Normalization (to 0-1 range)
        layers.Rescaling(1./255)
    ], name="data_augmentation")

def compute_class_weights(y):
    """
    Compute class weights for imbalanced datasets
    
    Args:
        y: Array of class labels
        
    Returns:
        Dictionary of class weights for model training
    """
    from sklearn.utils.class_weight import compute_class_weight
    
    # Get class distribution
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(y),
        y=y
    )
    
    # Convert to dictionary format
    class_weights = {i: weight for i, weight in enumerate(class_weights)}
    
    # Print class distribution
    print("\nüìä Class distribution:")
    unique, counts = np.unique(y, return_counts=True)
    for cls, count, weight in zip(unique, counts, class_weights.values()):
        print(f"  {SOIL_LABELS[cls]}: {count} samples (weight: {weight:.2f})")
    
    return class_weights

def setup_mixed_precision():
    """Setup mixed precision for faster GPU training"""
    # DISABLED for TFLite compatibility - mixed precision causes conversion issues
    print("‚ÑπÔ∏è Mixed precision disabled for maximum TFLite compatibility")
    print("üì± Using float32 training to ensure Flutter compatibility")
    
    # Ensure float32 policy is set
    tf.keras.mixed_precision.set_global_policy('float32')
    return False

def create_flutter_compatible_model():
    """
    Create an improved Flutter-compatible soil classification model
    
    Key improvements:
    - Better feature extraction with depthwise separable convolutions
    - Batch normalization for faster convergence
    - Enhanced regularization to prevent overfitting
    - Optimized for mobile deployment
    - Maintains TFLite compatibility
    """
    print("üèóÔ∏è Creating IMPROVED Flutter-compatible soil classification model...")
    print("üöÄ Architecture optimized for better accuracy and mobile performance")
    
    # Setup mixed precision for faster training
    mixed_precision_enabled = setup_mixed_precision()
    
    model = keras.Sequential([
        # Input layer with preprocessing
        layers.Input(shape=(INPUT_SIZE, INPUT_SIZE, 3), name='input'),
        
        # Initial convolution with larger receptive field
        layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same', activation='relu', name='conv1'),
        layers.BatchNormalization(),
        layers.Dropout(0.1, name='dropout1'),
        
        # Depthwise separable convolution block 1
        layers.SeparableConv2D(64, (3, 3), padding='same', activation='relu', name='sep_conv1'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2), name='pool1'),
        layers.Dropout(0.15, name='dropout2'),
        
        # Depthwise separable convolution block 2
        layers.SeparableConv2D(128, (3, 3), padding='same', activation='relu', name='sep_conv2'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2), name='pool2'),
        layers.Dropout(0.2, name='dropout3'),
        
        # Depthwise separable convolution block 3
        layers.SeparableConv2D(256, (3, 3), padding='same', activation='relu', name='sep_conv3'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2), name='pool3'),
        layers.Dropout(0.25, name='dropout4'),
        
        # Global pooling with attention
        layers.GlobalAveragePooling2D(name='global_pool'),
        
        # Enhanced classification head
        layers.Dense(512, activation='relu', kernel_regularizer='l2', name='dense1'),
        layers.Dropout(0.5, name='dropout5'),
        layers.BatchNormalization(),
        
        layers.Dense(256, activation='relu', kernel_regularizer='l2', name='dense2'),
        layers.Dropout(0.4, name='dropout6'),
        layers.BatchNormalization(),
        
        # Output layer with temperature scaling for better calibration
        layers.Dense(NUM_CLASSES, activation='softmax', dtype='float32', name='predictions')
    ])
    
    # Enhanced optimizer with better defaults
    optimizer = keras.optimizers.Adam(
        learning_rate=0.0005,  # Lower learning rate for better convergence
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-07
    )
    
    # Compile with additional metrics
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=[
            'accuracy',
            keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='top3_accuracy')
        ]
    )
    
    # Print model summary
    model.summary()
    print("‚úÖ IMPROVED Flutter-compatible model created")
    print(f"üìä Total parameters: {model.count_params():,}")
    print("üîç Model uses only TFLite-compatible operations")
    
    return model

def generate_synthetic_soil_data():
    """Generate synthetic soil images for training using GPU acceleration"""
    print("üé® Generating synthetic soil dataset...")
    
    # Check if GPU is available for data generation
    gpus = tf.config.list_physical_devices('GPU')
    use_gpu = len(gpus) > 0
    
    if use_gpu:
        print("‚ö° Using GPU acceleration for synthetic data generation")
    else:
        print("üîÑ Using CPU for synthetic data generation")
    
    @tf.function
    def create_soil_texture_gpu(soil_type, batch_size=100):
        """Create realistic soil texture using GPU operations"""
        
        # Base color ranges for different soil types (as tensors)
        color_ranges = tf.constant([
            [[0.4, 0.3, 0.2], [0.7, 0.5, 0.3]],  # Alluvial - brown
            [[0.1, 0.1, 0.1], [0.3, 0.3, 0.3]],  # Black - dark
            [[0.5, 0.2, 0.1], [0.8, 0.4, 0.2]],  # Red - reddish
            [[0.6, 0.3, 0.2], [0.9, 0.5, 0.3]],  # Laterite - orange-red
            [[0.7, 0.6, 0.4], [0.9, 0.8, 0.6]],  # Desert - sandy
            [[0.6, 0.6, 0.5], [0.8, 0.8, 0.7]],  # Saline - whitish
            [[0.2, 0.3, 0.1], [0.4, 0.5, 0.3]],  # Peaty - dark green
            [[0.3, 0.2, 0.1], [0.5, 0.4, 0.3]],  # Forest - rich brown
        ], dtype=tf.float32)
        
        min_color = color_ranges[soil_type, 0]
        max_color = color_ranges[soil_type, 1]
        
        # Generate base texture using GPU
        shape = (batch_size, INPUT_SIZE, INPUT_SIZE, 3)
        
        # Create base random texture
        base_texture = tf.random.uniform(shape, minval=0.0, maxval=1.0)
        
        # Apply color range
        color_range = max_color - min_color
        colored_texture = min_color + base_texture * color_range
        
        # Add noise for texture variation
        noise = tf.random.normal(shape, mean=0.0, stddev=0.1)
        textured = colored_texture + noise
        
        # Add granular patterns using convolution
        # Create random kernels for texture
        kernel = tf.random.normal((5, 5, 3, 3), stddev=0.1)
        granular = tf.nn.conv2d(textured, kernel, strides=[1, 1, 1, 1], padding='SAME')
        
        # Blend original with granular texture
        final_texture = 0.7 * textured + 0.3 * tf.nn.tanh(granular)
        
        # Clip to valid range
        final_texture = tf.clip_by_value(final_texture, 0.0, 1.0)
        
        return final_texture
    
    def create_soil_texture_cpu(soil_type, size=(INPUT_SIZE, INPUT_SIZE)):
        """Fallback CPU version for compatibility"""
        np.random.seed(42 + soil_type)
        
        color_ranges = {
            0: ([0.4, 0.3, 0.2], [0.7, 0.5, 0.3]),  # Alluvial - brown
            1: ([0.1, 0.1, 0.1], [0.3, 0.3, 0.3]),  # Black - dark
            2: ([0.5, 0.2, 0.1], [0.8, 0.4, 0.2]),  # Red - reddish
            3: ([0.6, 0.3, 0.2], [0.9, 0.5, 0.3]),  # Laterite - orange-red
            4: ([0.7, 0.6, 0.4], [0.9, 0.8, 0.6]),  # Desert - sandy
            5: ([0.6, 0.6, 0.5], [0.8, 0.8, 0.7]),  # Saline - whitish
            6: ([0.2, 0.3, 0.1], [0.4, 0.5, 0.3]),  # Peaty - dark green
            7: ([0.3, 0.2, 0.1], [0.5, 0.4, 0.3]),  # Forest - rich brown
        }
        
        min_color, max_color = color_ranges[soil_type]
        img = np.random.uniform(min_color[0], max_color[0], size + (3,))
        
        for i in range(3):
            channel = np.random.uniform(min_color[i], max_color[i], size)
            noise = np.random.normal(0, 0.1, size)
            channel = np.clip(channel + noise, 0, 1)
            
            for _ in range(10):  # Reduced iterations for speed
                x, y = np.random.randint(0, size[0]), np.random.randint(0, size[1])
                radius = np.random.randint(2, 6)
                xx, yy = np.meshgrid(np.arange(size[1]), np.arange(size[0]))
                mask = (xx - x)**2 + (yy - y)**2 < radius**2
                channel[mask] *= np.random.uniform(0.8, 1.2)
            
            img[:, :, i] = np.clip(channel, 0, 1)
        
        return img
    
    # Generate balanced dataset (memory-optimized for Colab)
    samples_per_class = 400  # Reduced to prevent memory allocation warnings
    total_samples = samples_per_class * NUM_CLASSES
    
    print(f"üìä Generating {samples_per_class} samples per class...")
    
    if use_gpu:
        # GPU-accelerated batch generation
        print("‚ö° Using GPU batch generation for maximum speed...")
        
        X_tensor_list = []
        y_tensor_list = []
        
        batch_size = 200  # Increased batch size for better GPU utilization
        
        for soil_type in range(NUM_CLASSES):
            print(f"üöÄ Generating {samples_per_class} samples for {SOIL_LABELS[soil_type]} (GPU)...")
            
            # Generate in batches and keep on GPU
            for batch_start in range(0, samples_per_class, batch_size):
                batch_end = min(batch_start + batch_size, samples_per_class)
                current_batch_size = batch_end - batch_start
                
                # Generate batch on GPU and keep it there
                batch_images = create_soil_texture_gpu(soil_type, current_batch_size)
                batch_labels = tf.fill([current_batch_size], soil_type)
                
                # Keep tensors on GPU
                X_tensor_list.append(batch_images)
                y_tensor_list.append(batch_labels)
            
            print(f"‚úÖ Generated {samples_per_class} samples for {SOIL_LABELS[soil_type]}")
        
        # Keep data on GPU and use TensorFlow for memory-efficient operations
        print("üîÄ Creating shuffled dataset directly on GPU...")
        
        # Concatenate all batches on GPU
        X_tensor = tf.concat(X_tensor_list, axis=0)
        y_tensor = tf.concat(y_tensor_list, axis=0)
        
        # Create dataset and shuffle on GPU - keep everything on GPU!
        print("üöÄ Creating GPU-only training pipeline...")
        dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))
        dataset = dataset.shuffle(buffer_size=min(10000, total_samples), seed=42)
        
        # Split into train/validation on GPU
        train_size = int(0.8 * total_samples)
        train_dataset = dataset.take(train_size)
        val_dataset = dataset.skip(train_size)
        
        print(f"üìà Training samples: {train_size}")
        print(f"üìâ Validation samples: {total_samples - train_size}")
        
        # Return GPU datasets instead of numpy arrays
        return train_dataset, val_dataset, total_samples
        
    else:
        # CPU fallback generation
        print("üîÑ Using CPU generation (slower but compatible)...")
        
        X = np.zeros((total_samples, INPUT_SIZE, INPUT_SIZE, 3), dtype=np.float32)
        y = np.zeros(total_samples, dtype=np.int32)
        
        for soil_type in range(NUM_CLASSES):
            start_idx = soil_type * samples_per_class
            end_idx = start_idx + samples_per_class
            
            print(f"üîÑ Generating {samples_per_class} samples for {SOIL_LABELS[soil_type]} (CPU)...")
            
            for i in range(samples_per_class):
                X[start_idx + i] = create_soil_texture_cpu(soil_type)
                y[start_idx + i] = soil_type
            
            print(f"‚úÖ Generated {samples_per_class} samples for {SOIL_LABELS[soil_type]}")
        
        # Simple shuffle for CPU-generated data
        print("üîÄ Shuffling dataset...")
        indices = np.random.permutation(len(X))
        X, y = X[indices], y[indices]
        
        # Split into train/validation
        from sklearn.model_selection import train_test_split
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"üìà Training samples: {len(X_train)}")
        print(f"üìâ Validation samples: {len(X_val)}")
        
        # Return numpy arrays for CPU path
        return (X_train, y_train), (X_val, y_val), len(X)
    
    print(f"‚úÖ Synthetic dataset created: {total_samples} samples")
    
    # Performance summary
    if use_gpu:
        print("‚ö° GPU acceleration used - everything stays on GPU!")
    else:
        print("üîÑ CPU generation completed - consider GPU for faster data creation")

def convert_to_flutter_tflite(model, output_path):
    """Convert model to Flutter-compatible TensorFlow Lite"""
    print("üì± Converting to Flutter-compatible TensorFlow Lite...")
    
    # Ensure float32 policy for TFLite conversion
    tf.keras.mixed_precision.set_global_policy('float32')
    
    # Create converter
    print("üîÑ Creating TFLite converter...")
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # CRITICAL: Use ONLY built-in TFLite ops for Flutter compatibility
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS  # Only standard TFLite operations
    ]
    
    # Enable optimizations for smaller model size
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    
    # Create representative dataset for quantization
    def representative_data_gen():
        """Generate representative data for quantization"""
        for _ in range(100):
            # Generate random data matching model input shape
            data = np.random.random((1, INPUT_SIZE, INPUT_SIZE, 3)).astype(np.float32)
            yield [data]
    
    converter.representative_dataset = representative_data_gen
    
    # Enable full integer quantization for smaller size and faster inference
    converter.target_spec.supported_types = [tf.int8]
    converter.inference_input_type = tf.uint8   # Flutter-friendly
    converter.inference_output_type = tf.uint8  # Flutter-friendly
    
    print("üîÑ Converting model (this may take a few minutes)...")
    
    try:
        # Primary conversion with quantization
        tflite_model = converter.convert()
        print("‚úÖ Model conversion successful with quantization!")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Quantized conversion failed: {e}")
        print("üîÑ Attempting without quantization for maximum compatibility...")
        
        # Fallback: Disable quantization for compatibility
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
        # No optimizations for maximum compatibility
        
        try:
            tflite_model = converter.convert()
            print("‚úÖ Float32 model conversion successful!")
        except Exception as e2:
            print(f"‚ùå Float32 conversion also failed: {e2}")
            print("üí° This suggests the model architecture may not be fully TFLite compatible")
            raise e2
    
    # Save model
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'wb') as f:
        f.write(tflite_model)
    
    # Model info
    model_size_mb = len(tflite_model) / (1024 * 1024)
    print(f"‚úÖ Flutter-compatible TFLite model saved: {output_path}")
    print(f"üìä Model size: {model_size_mb:.2f} MB")
    
    return tflite_model

def create_model_metadata(model_path, accuracy_metrics):
    """Create metadata file for the model"""
    metadata = {
        "model_name": MODEL_NAME,
        "version": "4.0.0",
        "created_at": datetime.now().isoformat(),
        "framework": "TensorFlow Lite",
        "flutter_compatible": True,
        "quantized": True,
        "input_shape": [1, INPUT_SIZE, INPUT_SIZE, 3],
        "input_type": "uint8",
        "output_shape": [1, NUM_CLASSES],
        "output_type": "uint8",
        "num_classes": NUM_CLASSES,
        "soil_labels": SOIL_LABELS,
        "accuracy_metrics": accuracy_metrics,
        "preprocessing": {
            "resize_to": [INPUT_SIZE, INPUT_SIZE],
            "normalize": "0-255 to 0-1 range",
            "color_space": "RGB"
        },
        "usage_notes": [
            "Model uses only TFLite built-in operations",
            "Compatible with Flutter tflite_flutter package",
            "Input images should be 224x224 RGB",
            "Output is probability distribution over 8 soil types"
        ]
    }
    
    metadata_path = model_path.replace('.tflite', '_info.json')
    
    try:
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        print(f"‚úÖ Model metadata saved: {metadata_path}")
        return metadata_path
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to save metadata: {e}")
        return None

def detect_colab():
    """Detect if running in Google Colab"""
    try:
        import google.colab
        return True
    except ImportError:
        return False

def setup_gpu_optimization():
    """Configure GPU for optimal performance"""
    print("üöÄ Setting up GPU optimization...")
    
    # Get available GPUs
    gpus = tf.config.list_physical_devices('GPU')
    
    if gpus:
        try:
            # Enable memory growth to prevent GPU memory allocation issues
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            
            # Set GPU as preferred device
            tf.config.set_visible_devices(gpus, 'GPU')
            
            print(f"‚úÖ GPU optimization enabled for {len(gpus)} device(s)")
            
            # Check GPU memory
            try:
                import subprocess
                result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total,memory.free', '--format=csv,nounits,noheader'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    lines = result.stdout.strip().split('\n')
                    for i, line in enumerate(lines):
                        total, free = line.split(', ')
                        print(f"   GPU {i}: {free}MB free / {total}MB total")
                        
                        # Auto-adjust batch size based on GPU memory
                        if AUTO_BATCH_SIZE:
                            free_gb = int(free) / 1024
                            if free_gb >= 8:
                                suggested_batch = MAX_BATCH_SIZE
                            elif free_gb >= 6:
                                suggested_batch = 96
                            elif free_gb >= 4:
                                suggested_batch = 80
                            elif free_gb >= 2:
                                suggested_batch = 64
                            else:
                                suggested_batch = 48  # Increased minimum for better GPU utilization
                            
                            global BATCH_SIZE
                            BATCH_SIZE = suggested_batch
                            print(f"   üéØ Auto-adjusted batch size to {BATCH_SIZE} based on {free_gb:.1f}GB free memory")
                else:
                    print("   GPU memory info not available")
            except:
                print("   GPU memory info not available")
                
            return True
            
        except RuntimeError as e:
            print(f"‚ö†Ô∏è GPU setup warning: {e}")
            print("   Continuing with default GPU settings...")
            return True
    else:
        print("‚ùå No GPU detected - training will use CPU (much slower)")
        print("üí° In Colab: Runtime > Change runtime type > GPU")
        return False

def setup_colab_environment():
    """Setup Google Colab environment"""
    if detect_colab():
        print("üîß Setting up Google Colab environment...")
        
        # Install required packages
        import subprocess
        import sys
        
        packages = ['tensorflow>=2.13.0', 'matplotlib', 'numpy', 'scikit-learn', 'pillow']
        for package in packages:
            try:
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
            except:
                print(f"‚ö†Ô∏è Could not install {package}, assuming it's already available")
        
        print("‚úÖ Colab environment setup complete")
        return True
    return False

def setup_dataset_choice():
    """Setup dataset choice interface"""
    print("\nüìä Dataset Selection:")
    print("=" * 60)
    print("Choose your training dataset:")
    print("1. üì§ Upload real soil images (ZIP file)")
    print("2. üé® Generate synthetic soil dataset")
    print("3. üîÑ Mixed dataset (synthetic + real)")
    print()
    
    if detect_colab():
        try:
            choice = input("Enter choice (1/2/3): ").strip()
            return choice
        except:
            print("‚ö†Ô∏è Input not available, defaulting to synthetic dataset")
            return "2"
    else:
        # Check for local dataset
        if check_local_dataset():
            return "1"  # Use real data if available locally
        else:
            return "2"  # Default to synthetic

def setup_dataset_upload():
    """Setup dataset upload interface for Colab"""
    try:
        from google.colab import files
        
        print("üì§ Upload your soil dataset ZIP file...")
        print("Expected structure inside ZIP:")
        for soil_type in SOIL_LABELS.values():
            folder_name = soil_type.replace('/', '_').replace(' ', '_')
            print(f"   üìÅ {folder_name}/")
            print(f"      üì∑ image1.jpg, image2.jpg, ...")
        print()
        
        uploaded = files.upload()
        
        if uploaded:
            # Extract the first ZIP file found
            for filename in uploaded.keys():
                if filename.endswith('.zip'):
                    print(f"üì¶ Extracting {filename}...")
                    return extract_dataset(filename)
                    
        print("‚ùå No ZIP file uploaded.")
        return False
        
    except ImportError:
        print("‚ÑπÔ∏è Not in Colab environment")
        return False

def check_local_dataset():
    """Check for local dataset directory"""
    dataset_paths = ['soil_dataset', 'real_soil_dataset', 'dataset', 'data']
    
    for path in dataset_paths:
        if os.path.exists(path):
            print(f"‚úÖ Found local dataset at: {path}")
            return True
    
    return False

def extract_dataset(zip_filename):
    """Extract uploaded dataset ZIP file"""
    try:
        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
            zip_ref.extractall('uploaded_dataset')
        
        # Find the actual dataset folder
        dataset_root = 'uploaded_dataset'
        subdirs = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]
        
        if len(subdirs) == 1:
            # Dataset is in a subfolder
            dataset_root = os.path.join(dataset_root, subdirs[0])
        
        # Verify dataset structure
        soil_folders = []
        for soil_type in SOIL_LABELS.values():
            folder_name = soil_type.replace('/', '_').replace(' ', '_')
            folder_path = os.path.join(dataset_root, folder_name)
            if os.path.exists(folder_path):
                soil_folders.append(folder_path)
        
        if len(soil_folders) >= 4:  # At least half the soil types
            print(f"‚úÖ Dataset extracted successfully! Found {len(soil_folders)} soil type folders")
            return True
        else:
            print(f"‚ö†Ô∏è Dataset structure incomplete. Found only {len(soil_folders)} soil type folders")
            return False
            
    except Exception as e:
        print(f"‚ùå Error extracting dataset: {e}")
        return False

def load_real_dataset():
    """Load real soil images from uploaded/local dataset"""
    print("üìÇ Loading real soil dataset...")
    
    # Find dataset directory
    dataset_paths = ['uploaded_dataset', 'soil_dataset', 'real_soil_dataset', 'dataset', 'data']
    dataset_root = None
    
    for path in dataset_paths:
        if os.path.exists(path):
            dataset_root = path
            break
    
    if not dataset_root:
        print("‚ùå No dataset directory found")
        return None, None
    
    # Check for subdirectory
    subdirs = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]
    if len(subdirs) == 1 and not any(soil_type.replace('/', '_').replace(' ', '_') in subdirs[0] for soil_type in SOIL_LABELS.values()):
        dataset_root = os.path.join(dataset_root, subdirs[0])
    
    X_list = []
    y_list = []
    
    for soil_idx, soil_type in SOIL_LABELS.items():
        folder_name = soil_type.replace('/', '_').replace(' ', '_')
        folder_path = os.path.join(dataset_root, folder_name)
        
        if not os.path.exists(folder_path):
            print(f"‚ö†Ô∏è Folder not found: {folder_path}")
            continue
        
        # Load images from this soil type folder
        image_files = [f for f in os.listdir(folder_path) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            print(f"‚ö†Ô∏è No images found in: {folder_path}")
            continue
        
        print(f"üì∑ Loading {len(image_files)} images for {soil_type}...")
        
        for img_file in image_files[:500]:  # Limit to 500 images per class
            try:
                img_path = os.path.join(folder_path, img_file)
                
                # Load and preprocess image
                img = Image.open(img_path).convert('RGB')
                img = img.resize((INPUT_SIZE, INPUT_SIZE))
                img_array = np.array(img) / 255.0  # Normalize to [0, 1]
                
                X_list.append(img_array)
                y_list.append(soil_idx)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading {img_file}: {e}")
                continue
    
    if not X_list:
        print("‚ùå No images loaded successfully")
        return None, None
    
    X = np.array(X_list, dtype=np.float32)
    y = np.array(y_list, dtype=np.int32)
    
    print(f"‚úÖ Real dataset loaded: {len(X)} images, {len(np.unique(y))} soil types")
    
    # Show distribution
    unique, counts = np.unique(y, return_counts=True)
    for soil_idx, count in zip(unique, counts):
        print(f"   {SOIL_LABELS[soil_idx]}: {count} images")
    
    return X, y

def main():
    """Main training pipeline"""
    print("üå± Flutter-Compatible Soil Detection Model Training")
    print("=" * 60)
    
    # Setup environment and GPU optimization
    in_colab = setup_colab_environment()
    gpu_available = setup_gpu_optimization()
    
    # Create output directory (Colab-friendly path)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if in_colab:
        output_dir = f"flutter_compatible_{timestamp}"  # Colab root directory
    else:
        output_dir = f"../models/flutter_compatible_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    
    # Dataset selection and loading
    print("\nüìä Step 1: Dataset Selection & Loading")
    dataset_choice = setup_dataset_choice()
    
    X, y = None, None
    
    if dataset_choice == "1":
        # Real dataset
        if in_colab:
            if setup_dataset_upload():
                X, y = load_real_dataset()
        else:
            X, y = load_real_dataset()
        
        if X is None:
            print("‚ö†Ô∏è Real dataset loading failed. Falling back to synthetic data.")
            X, y = generate_synthetic_soil_data()
    
    elif dataset_choice == "3":
        # Mixed dataset
        print("üîÑ Creating mixed dataset (synthetic + real)...")
        
        # Try to load real data first
        X_real, y_real = None, None
        if in_colab:
            if setup_dataset_upload():
                X_real, y_real = load_real_dataset()
        else:
            X_real, y_real = load_real_dataset()
        
        # Generate synthetic data
        X_synthetic, y_synthetic = generate_synthetic_soil_data()
        
        # Combine datasets
        if X_real is not None:
            print(f"üìä Combining {len(X_real)} real + {len(X_synthetic)} synthetic images")
            X = np.concatenate([X_real, X_synthetic], axis=0)
            y = np.concatenate([y_real, y_synthetic], axis=0)
        else:
            print("‚ö†Ô∏è No real data available, using synthetic only")
            X, y = X_synthetic, y_synthetic
    
    else:
        # Synthetic dataset (default)
        print("üé® Generating synthetic soil dataset...")
        result = generate_synthetic_soil_data()
    
    # Handle different return types (GPU datasets vs CPU numpy arrays)
    if len(result) == 3 and hasattr(result[0], 'batch'):  # GPU datasets
        train_dataset, val_dataset, total_samples = result
        
        # Prepare datasets for training
        train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
        val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
        
        print(f"‚úÖ GPU-only pipeline ready: {total_samples} total samples")
        use_gpu_datasets = True
        
    else:  # CPU numpy arrays or mixed datasets
        if len(result) == 3:  # CPU path
            (X_train, y_train), (X_val, y_val), total_samples = result
        else:  # Mixed dataset path (fallback)
            X, y = result
            # Shuffle and split
            indices = np.random.permutation(len(X))
            X, y = X[indices], y[indices]
            
            print(f"‚úÖ Final dataset: {len(X)} images, {len(np.unique(y))} soil types")
            
            X_train, X_val, y_train, y_val = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            print(f"üìà Training samples: {len(X_train)}")
            print(f"üìâ Validation samples: {len(X_val)}")
        
        use_gpu_datasets = False
    
    # Create model
    print("\nüèóÔ∏è Step 2: Model Creation")
    model = create_flutter_compatible_model()
    
    # Prepare callbacks
    print("\nüöÄ Step 3: Model Training")
    
    # Create model checkpoint path
    checkpoint_path = os.path.join(output_dir, 'best_model.weights.h5')
    
    # Define callbacks
    callbacks = [
        # Model checkpoint
        tf.keras.callbacks.ModelCheckpoint(
            filepath=checkpoint_path,
            monitor='val_accuracy',
            save_best_only=True,
            save_weights_only=True,
            mode='max',
            verbose=1
        ),
        # Early stopping
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=PATIENCE,
            min_delta=MIN_DELTA,
            restore_best_weights=True,
            verbose=1
        ),
        # Learning rate scheduler
        tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1),
        # TensorBoard
        tf.keras.callbacks.TensorBoard(
            log_dir=os.path.join(output_dir, 'logs'),
            histogram_freq=1,
            update_freq='batch',
            profile_batch=0  # Disable profiling for better performance
        )
    ]
    
    # Compute class weights if using real data
    class_weights = None
    if 'y_train' in locals() and not use_gpu_datasets:
        class_weights = compute_class_weights(y_train)
    
    # Performance estimates and training info
    print("\nüìä Training Configuration:")
    print(f"   ‚Ä¢ Epochs: {EPOCHS}")
    print(f"   ‚Ä¢ Batch size: {BATCH_SIZE}")
    print(f"   ‚Ä¢ Learning rate: {LEARNING_RATE}")
    print(f"   ‚Ä¢ Early stopping patience: {PATIENCE}")
    print(f"   ‚Ä¢ Using data augmentation: {'Yes' if not use_gpu_datasets else 'Built-in'}")
    print(f"   ‚Ä¢ Using class weights: {'Yes' if class_weights is not None else 'No'}")
    
    if gpu_available:
        estimated_time = EPOCHS * 1.2  # 1.2 minutes per epoch with GPU and optimizations
        print(f"‚ö° GPU-accelerated training enabled")
        print(f"üìä Using batch size: {BATCH_SIZE}")
        print(f"‚è±Ô∏è Estimated training time: ~{estimated_time:.0f} minutes")
    else:
        estimated_time = EPOCHS * 8   # 8 minutes per epoch with CPU
        print(f"üêå CPU training (consider enabling GPU for 5x speedup)")
        print(f"‚è±Ô∏è Estimated training time: ~{estimated_time:.0f} minutes")
    
    # Enhanced callbacks for faster training
    callbacks = [
        keras.callbacks.EarlyStopping(
            patience=15, 
            restore_best_weights=True,
            monitor='val_accuracy',
            mode='max',
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            patience=7, 
            factor=0.5,
            min_lr=1e-7,
            monitor='val_loss',
            verbose=1
        ),
        keras.callbacks.ModelCheckpoint(
            filepath=os.path.join(output_dir, 'best_model.h5'),
            save_best_only=True,
            monitor='val_accuracy',
            mode='max',
            verbose=0
        )
    ]
    
    if not use_gpu_datasets:
        print(f"üéØ Training with {len(X_train)} samples, validating with {len(X_val)} samples")
    else:
        print(f"üéØ Training with GPU datasets (no CPU RAM usage)")
    print("üöÄ Starting training...")
    
    # Start training with optimized settings
    start_time = datetime.now()
    
    # Train with appropriate data format
    if use_gpu_datasets:
        print("üöÄ Training with GPU-only pipeline (no CPU RAM usage)...")
        history = model.fit(
            train_dataset,
            epochs=EPOCHS,
            validation_data=val_dataset,
            callbacks=callbacks,
            verbose=1
        )
    else:
        print("üîÑ Training with CPU/mixed data...")
        history = model.fit(
            X_train, y_train,
            batch_size=BATCH_SIZE,
            epochs=EPOCHS,
            validation_data=(X_val, y_val),
            callbacks=callbacks,
            verbose=1,
            shuffle=True
        )
    
    end_time = datetime.now()
    actual_time = (end_time - start_time).total_seconds() / 60
    print(f"‚úÖ Training completed in {actual_time:.1f} minutes (estimated: {estimated_time:.0f})")
    
    # Evaluate model
    print("\nüìä Step 4: Model Evaluation")
    if use_gpu_datasets:
        print("üìä Evaluating GPU-only pipeline...")
        train_loss, train_acc = model.evaluate(train_dataset, verbose=0)
        val_loss, val_acc = model.evaluate(val_dataset, verbose=0)
    else:
        train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    
    print(f"üìà Training Accuracy: {train_acc:.4f}")
    print(f"üìâ Validation Accuracy: {val_acc:.4f}")
    
    # Convert to TFLite
    print("\nüì± Step 5: TensorFlow Lite Conversion")
    model_path = os.path.join(output_dir, f"{MODEL_NAME}.tflite")
    tflite_model = convert_to_flutter_tflite(model, model_path)
    
    # Create metadata
    print("\nüìÑ Step 6: Metadata Creation")
    
    # Handle different data formats for metadata
    if use_gpu_datasets:
        # For GPU datasets, we know the total samples from the generation
        total_samples_count = total_samples if 'total_samples' in locals() else 3200  # Default from 400*8
        training_samples_count = int(0.8 * total_samples_count)
        validation_samples_count = total_samples_count - training_samples_count
    else:
        # For numpy arrays
        total_samples_count = len(X) if 'X' in locals() else len(X_train) + len(X_val)
        training_samples_count = len(X_train)
        validation_samples_count = len(X_val)
    
    accuracy_metrics = {
        "training_accuracy": float(train_acc),
        "validation_accuracy": float(val_acc),
        "training_loss": float(train_loss),
        "validation_loss": float(val_loss),
        "dataset_type": "real" if dataset_choice == "1" else ("mixed" if dataset_choice == "3" else "synthetic"),
        "total_samples": total_samples_count,
        "training_samples": training_samples_count,
        "validation_samples": validation_samples_count,
        "gpu_pipeline": use_gpu_datasets
    }
    metadata_path = create_model_metadata(model_path, accuracy_metrics)
    
    # Save training plots
    print("\nüìä Step 7: Saving Training Plots")
    
    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training')
    plt.plot(history.history['val_accuracy'], label='Validation')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training')
    plt.plot(history.history['val_loss'], label='Validation')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.tight_layout()
    plot_path = os.path.join(output_dir, 'training_history.png')
    
    try:
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()  # Close the figure to free memory
        print(f"‚úÖ Training plots saved: {plot_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to save training plots: {e}")
        plot_path = None
    
    # Final summary
    print("\nüéâ Training Complete!")
    print("=" * 60)
    print(f"üìÅ Output directory: {output_dir}")
    print(f"üì± TFLite model: {model_path}")
    print(f"üìÑ Metadata: {metadata_path}")
    print(f"üìä Training plots: {plot_path}")
    print(f"üéØ Validation accuracy: {val_acc:.4f}")
    print("\nüì± Model is ready for Flutter integration!")
    print("üîß Copy the .tflite file to your Flutter app's assets/models/ directory")
    
    # Copy model to current directory for easier access
    import shutil
    current_dir_model = f"{MODEL_NAME}.tflite"
    try:
        shutil.copy2(model_path, current_dir_model)
        print(f"üìÅ Model copied to current directory: {current_dir_model}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not copy model to current directory: {e}")
    
    # Colab download instructions
    if in_colab:
        # Handle None values for failed file creation
        safe_metadata_path = metadata_path if metadata_path else model_path.replace('.tflite', '_info.json')
        safe_plot_path = plot_path if plot_path else os.path.join(output_dir, "training_history.png")
        show_colab_download_instructions(model_path, safe_metadata_path, safe_plot_path)
        
    # Test Flutter compatibility
    print("\nüß™ Testing Flutter compatibility of generated model...")
    try:
        import subprocess
        
        # Download the test script if it doesn't exist
        test_script = "test_flutter_compatibility.py"
        if not os.path.exists(test_script):
            subprocess.run([
                "wget", "-O", test_script,
                "https://raw.githubusercontent.com/ctopuviyan/puviyan-ai-training/main/scripts/test_flutter_compatibility.py"
            ], check=True)
        
        # Run the compatibility test on the copied model
        result = subprocess.run([
            "python", test_script, current_dir_model
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("‚úÖ Flutter compatibility test passed!")
            print(result.stdout)
        else:
            print("‚ö†Ô∏è Flutter compatibility test had issues:")
            print(result.stderr)
            
    except Exception as e:
        print(f"‚ö†Ô∏è Could not run Flutter compatibility test: {e}")
        print(f"üí° You can manually test with: python test_flutter_compatibility.py {current_dir_model}")

def show_colab_download_instructions(model_path, metadata_path, plot_path):
    """Show download instructions for Google Colab"""
    print("\nüì• Google Colab Download Instructions:")
    print("=" * 60)
    print("üîΩ Download your trained model files:")
    print()
    
    try:
        from google.colab import files
        
        # Check if files exist before trying to download
        if model_path and os.path.exists(model_path):
            print("üì± Downloading TFLite model...")
            files.download(model_path)
        else:
            print(f"‚ö†Ô∏è Model file not found: {model_path}")
        
        if metadata_path and os.path.exists(metadata_path):
            print("üìÑ Downloading metadata...")
            files.download(metadata_path)
        else:
            print(f"‚ö†Ô∏è Metadata file not found or path is None: {metadata_path}")
        
        if plot_path and os.path.exists(plot_path):
            print("üìä Downloading training plots...")
            files.download(plot_path)
        else:
            print(f"‚ö†Ô∏è Plot file not found or path is None: {plot_path}")
        
        print("‚úÖ Available files downloaded successfully!")
        
    except ImportError:
        print("‚ö†Ô∏è Not in Colab environment, skipping auto-download")
    except Exception as e:
        print(f"‚ö†Ô∏è Auto-download failed: {e}")
        print("üìã Manual download commands:")
        print(f"   files.download('{model_path}')")
        print(f"   files.download('{metadata_path}')")
        print(f"   files.download('{plot_path}')")
    
    print("\nüöÄ Next Steps:")
    print("1. üì± Copy the .tflite file to your Flutter app: assets/models/")
    print("2. üîß Update your Flutter app to use the new model")
    print("3. üß™ Test the model with real soil images")
    print("4. üìä Monitor performance on target devices")

if __name__ == "__main__":
    main()
